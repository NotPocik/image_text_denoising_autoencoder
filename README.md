В ноутбуке autoencoder_models обучал все модели (в google colab), он довольно кривой и непоследовательный местами, тк много чего в нем изменял и удалял. Сохранил всего 4 модели:
   - autoencoder.keras - самая простая из моделей, по 2 сверточных слоя в энкодере и декодере, струкрура создавалась функцией build_autoencoder_simple() (в ноутбуке можно посмотреть), loss функция - binary_crossentropy;
   - autoencoder_bce.keras - модель на основе U-Net, но без соединения сверточных слоев энкодера и декодера, loss функция - binary_crossentropy;
   - autoencoder_bce_2.keras - модель на основе U-Net, в отличие от предыдущей сверточные слои энкодера и декодера соединены, из-за чего изображение выходит чуть более четким и детальным, loss функция - binary_crossentropy;
   - autoencoder_ssim.keras - модель на основе U-Net, сверточные слои энкодера и декодера соединены, loss функция - ssim, визульно работает лучше всех на тестовой и обучающей выборках, и с точки зрения очистки от дефектов, и с точки зрения четкости и резкости букв текста.

Во все модели подаются изображения размером 540x540, и возвращают они изображения в этом же размере, приведение всех изображений к этому размеру делал через cv2.resize(), но возможно потом будет лучше это сделать через добавление отступов.
Шумы дополнительно не добавлял на изображения пока что.

В ноутбуке autoencoder_test есть визуальное сравнение всех четырех моделей на случайных картинках из тестовой выборки, а также можно отдельно посмотреть на работу каждой модели на обучающей выборке.
Пытался еще сделать объективную оценку всех моделей по метрике ssim, но что-то не вышло.  
